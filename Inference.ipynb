{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file and checks the important fields for our device, and returns True if the data\n",
    "# is valid and false otherwise.\n",
    "def validate_dicom_file(filename): \n",
    "    print('Validate file {} ...'.format(filename))\n",
    "    ds = pydicom.dcmread(filename) \n",
    "    # check the validity of each DICOM file by analyzing the fields: image position, image type and body part.\n",
    "    body_part_examined = ds.BodyPartExamined\n",
    "    modality = ds.Modality\n",
    "    patient_position = ds.PatientPosition\n",
    "    \n",
    "    return body_part_examined == 'CHEST' and modality == 'DX' and patient_position in ['AP', 'PA']\n",
    "    \n",
    "    \n",
    "# This function reads in a .dcm file, and returns a numpy array\n",
    "# of just the imaging data    \n",
    "def get_pixel_array(filename): \n",
    "    print('Load file {} ...'.format(filename))\n",
    "    ds = pydicom.dcmread(filename)       \n",
    "    img = ds.pixel_array\n",
    "    \n",
    "    return img\n",
    "    \n",
    "    \n",
    "# This function takes the numpy array output by get_pixel_array and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img, img_size): \n",
    "    img = img / 255.0  \n",
    "    proc_img = np.zeros((1024,1024,3))\n",
    "    \n",
    "    proc_img[:, :, 0] = img\n",
    "    proc_img[:, :, 1] = img\n",
    "    proc_img[:, :, 2] = img\n",
    "    proc_img = np.resize(proc_img, img_size)\n",
    "    \n",
    "    return proc_img\n",
    "\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path, weight_path):\n",
    "    with open(model_path, 'r') as json_file:\n",
    "        json_savedModel = json_file.read()\n",
    "    model = tf.keras.models.model_from_json(json_savedModel)\n",
    "    model.load_weights(weight_path)\n",
    "    loss = 'binary_crossentropy'\n",
    "    model.compile(loss=loss)    \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    pred_Y = model.predict(img, batch_size = 1, verbose = True)\n",
    "    prediction = pred_Y > thresh\n",
    "    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate file test1.dcm ...\n",
      "Load file test1.dcm ...\n",
      "1/1 [==============================] - 2s 2s/sample\n",
      "[[ True]]\n",
      "Validate file test2.dcm ...\n",
      "Load file test2.dcm ...\n",
      "1/1 [==============================] - 0s 26ms/sample\n",
      "[[ True]]\n",
      "Validate file test3.dcm ...\n",
      "Load file test3.dcm ...\n",
      "1/1 [==============================] - 0s 26ms/sample\n",
      "[[ True]]\n",
      "Validate file test4.dcm ...\n",
      "Validate file test5.dcm ...\n",
      "Validate file test6.dcm ...\n"
     ]
    }
   ],
   "source": [
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "model_path = \"my_model.json\"\n",
    "weight_path = 'xray_class_my_model.best.hdf5'\n",
    "\n",
    "IMG_SIZE=(1,224,224,3) # This might be different if you did not use vgg16\n",
    "\n",
    "my_model = load_model(model_path, weight_path) #loads model\n",
    "thresh = 0.3535353535353536 #loads the threshold they chose for model classification \n",
    "\n",
    "# use the .dcm files to test your prediction\n",
    "for i in test_dicoms:\n",
    "    is_valid = validate_dicom_file(i)\n",
    "    \n",
    "    if not is_valid:\n",
    "        continue\n",
    "    \n",
    "    img = get_pixel_array(i)\n",
    "        \n",
    "    img_proc = preprocess_image(img, IMG_SIZE)\n",
    "    pred = predict_image(my_model,img_proc,thresh)\n",
    "    print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
